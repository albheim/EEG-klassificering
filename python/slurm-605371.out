data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J 2chs5
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:4

# use 5 cores per GPU
#SBATCH -n 20
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="conv2d_spect.py"
echo "py file"
cat $PY_FILE

echo "data file"
cat "data.py"

echo "mat file"
cat "../matlab/save transformed/savetf.m"

echo "nvidia smi"
nvidia-smi

echo "start time"
date

cp -r "${DATA_DIR}/DATA" $SNIC_TMP
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

matlab -nodisplay -nosplash -nodesktop -r "run('../matlab/save transformed/savetf.m');"
python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import Lambda
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import ELU, Activation, Flatten

from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_spect([5])

splits = 10

# channels = [4, 23]
# for i in range(n_subs):
#     x[i] = x[i][:, :, channels]
#     xt[i] = xt[i][:, :, channels]


m_in = Input(shape=x[0][0].shape)

m_t = Conv2D(4, (8, 8), padding='same')(m_in)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((4, 2))(m_t)
m_t = Dropout(0.2)(m_t)

m_t = Conv2D(8, (8, 8), padding='same')(m_t)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((4, 2))(m_t)
m_t = Dropout(0.3)(m_t)

m_t = Conv2D(16, (8, 8), padding='same')(m_t)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 2))(m_t)
m_t = Dropout(0.4)(m_t)

m_t = Flatten()(m_t)
m_t = Dense(15)(m_t)
#m_t = BatchNormalization()(m_t)
m_t = Activation('tanh')(m_t)
m_out = Dense(3, activation='softmax')(m_t)

model = Model(inputs=m_in, outputs=m_out)

m_save = model.get_config()
model.summary()

acc = 0
for tr, val in util.kfold(len(x[0]), splits, shuffle=True):

    model = Model.from_config(m_save)
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    # fit with next kfold data
    h = model.fit(x[0][tr], y[0][tr],
                  #validation_data=(x[val], y[val]),
                  batch_size=16, epochs=50, verbose=0)

    _, a = model.evaluate(x[0][val], y[0][val], verbose=0)
    acc += a

acc /= splits

print("avg accuracy {} over {} splits".format(acc, splits))
data file
import sys

import numpy as np
from scipy import io
import h5py

def load_single_sub(sub, cut=True, study=True, shuffle=True, visual=True, transpose=False):
    snic_tmp = "C:/Users/Albin Heimerson/Desktop/exjobb"
    if len(sys.argv) > 1:
        snic_tmp = str(sys.argv[1])
    xn = None
    yn = None
    names = ["FA", "LM", "OB"]
    for i in range(3):
        name = "Subj{:02}_CleanData_{}_{}".format(sub,
                                                  'study' if study else 'test',
                                                  names[i])
        if not study:
            name += "_{}".format("visual" if visual else "lexical")

        print("loading: ", name)
        m = io.loadmat('{}/DATA/{}/{}.mat'.format(snic_tmp,
                                                  "Visual" if visual else "Verbal",
                                                  name))
        trials = m[name][0][0][2][0]
        for j in range(trials.shape[0]):
            if cut:
                trials[j] = trials[j][:, 768:1536]
            if transpose:
                trials[j] = trials[j].T
        labels = np.zeros((trials.shape[0], 3))
        labels[:, i] = 1
        if xn is None:
            xn = trials
            yn = labels
        else:
            xn = np.concatenate((xn, trials), axis=0)
            yn = np.concatenate((yn, labels), axis=0)

    xn = np.stack(xn, axis=0)
    n = xn.shape[0]
    s = np.arange(n)
    if shuffle:
        np.random.shuffle(s)

    return (xn[s], yn[s])


def load_single(idx=None, cut=True, shuffle=True, visual=True, transpose=False,
                study=True):
    x = []
    y = []

    if idx is None:
        if visual:
            idx = [i if i < 10 else i + 1 for i in range(1, 19)]
        else:
            idx = [1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22]

    for sub in idx:
        xn, yn = load_single_sub(sub, cut, study, shuffle, visual, transpose)
        x.append(xn)
        y.append(yn)

    return (x, y)


def load_all(cut=True, visual=True):
    x = None
    y = None

    if visual:
        subs = [i if i < 10 else i + 1 for i in range(1, 19)]
    else:
        subs = [1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22]

    for sub in subs:  # 19 is max
        xn, yn = load_single_sub(sub, cut, visual)
        if x is None:
            x = xn
            y = yn
        else:
            x = np.concatenate((x, x), axis=0)
            y = np.concatenate((y, y), axis=0)

    print(x.shape, y.shape)
    x = np.stack(x, axis=0)
    print(x.shape)
    s = np.arange(x.shape[0])
    np.random.shuffle(s)

    return (x[s], y[s])


def load_marg(cut=None, visual=True, shuffle=True):
    snic_tmp = "C:/Users/Albin Heimerson/Desktop/exjobb"
    if len(sys.argv) > 1:
        snic_tmp = str(sys.argv[1])
    x = []
    y = []
    if visual:
        subs = [i if i < 10 else i + 1 for i in range(1, 19)]
    else:
        subs = [1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22]
    for sub in subs:
        xn = None
        yn = None
        for i in range(3):
            name = "Subj{:02}_{}_marg".format(sub, "Visual" if visual else "Verbal")
            print("loading: ", name)
            m = io.loadmat('{}/DATA/Modified/marginal/{}.mat'.format(snic_tmp, name))

            trials = m['data'][0][0][i][:, 0]
            if cut is not None:
                for j in range(trials.shape[0]):
                    trials[j] = trials[j][:, cut[0]:cut[1]]
            labels = np.zeros((trials.shape[0], 3))
            labels[:, i] = 1
            if xn is None:
                xn = trials
                yn = labels
            else:
                xn = np.concatenate((xn, trials), axis=0)
                yn = np.concatenate((yn, labels), axis=0)

        xn = np.stack(xn, axis=0)
        n = xn.shape[0]
        s = np.arange(n)
        if shuffle:
            np.random.shuffle(s)
        x.append(xn[s])
        y.append(yn[s])

    print(x[0].shape)
    return (x, y)


def cut(data, cut=[768, 1536], tcut = None):
    if tcut is not None:
        cut[0] = int(512 * tcut[0] + 768)
        cut[1] = int(512 * tcut[1] + 768)
    print(cut)
    for sub in range(len(data)):
        data[sub] = data[sub][:, :, cut[0]:cut[1]]


def modify(x, y, n, nmult=0, displacement=0, cut=[768, 1536]):
    mdata = [None for i in range(len(x))]
    my = [None for i in range(len(x))]
    for sub in range(len(mdata)):
        s = x[sub].shape[0]
        my[sub] = np.zeros((s * n, 3))
        for j in range(0, s * n, s):
            my[sub][j:j + s] = y[sub]
        mdata[sub] = np.zeros((s * n, x[sub].shape[1], cut[1] - cut[0]))
        mdata[sub][:s, :, :] = x[sub][:, :, cut[0]:cut[1]]
        for j in range(s, s * n, s):
            for i in range(len(x[sub])):
                if displacement > 0:
                    d = np.random.randint(-displacement, displacement + 1)
                    mdata[sub][j:j + s, :, :] = x[sub][:, :, cut[0] + d:cut[1] + d]

                if nmult != 0:
                    for k in range(mdata[sub][i].shape[0]):
                        mdata[sub][j + i, k] += nmult * np.std(mdata[sub][i, k]) * np.random.ranf(mdata[sub][i, k].shape)

    return mdata, my


def load_spect(idx):
    snic_tmp = "C:/Users/Albin Heimerson/Desktop/exjobb"
    if len(sys.argv) > 1:
        snic_tmp = str(sys.argv[1])
    x = []
    y = []
    for sub in idx:
        fname = '{}/DATA/Modified/spectogram/U{}.mat'.format(snic_tmp, sub)
        print(fname)
        with h5py.File(fname) as f:
            t = f['Y']
            print(t.shape)
            yn = np.zeros((t.shape[1], 3))
            for i in range(t.shape[1]):
                yn[i, int(t[0, i]) - 1] = 1

            y.append(yn)

            t = f['X']
            print(t.shape)
            xn = np.zeros(tuple([t.shape[1]]) + f[t[0, 0]].shape)
            for i in range(t.shape[1]):
                print(f[t[0, i]].shape)
                xn[i] = np.array(f[t[0, i]])

            print(xn.shape)
            xn = xn[:, :, :, np.newaxis]

            print(xn.shape)
            print(xn[0].shape)
            x.append(xn)

    return (x, y)


def load_spect_downsample(visual=True, shuffle=True, ds=8):
    snic_tmp = "C:/Users/Albin Heimerson/Desktop/exjobb"
    if len(sys.argv) > 1:
        snic_tmp = str(sys.argv[1])
    x = []
    y = []
    if visual:
        subs = [i if i < 10 else i + 1 for i in range(2, 19)] # change to 1
    else:
        subs = [1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22]
    for sub in subs:
        xn = None
        yn = None
        for i in range(3):
            name = "Subj{:02}_{}_spec{}".format(sub, "Visual" if visual else "Verbal", ds)
            print("loading: ", name)
            m = io.loadmat('{}/DATA/Modified/spect_downsample/{}.mat'.format(snic_tmp, name))

            trials = m['data'][0][0][i][:, 0]
            labels = np.zeros((trials.shape[0], 3))
            labels[:, i] = 1
            if xn is None:
                xn = trials
                yn = labels
            else:
                xn = np.concatenate((xn, trials), axis=0)
                yn = np.concatenate((yn, labels), axis=0)

        xn = np.stack(xn, axis=0)
        n = xn.shape[0]
        s = np.arange(n)
        if shuffle:
            np.random.shuffle(s)
        x.append(xn[s])
        y.append(yn[s])

    print(x[0].shape)
    return (x, y)
mat file
clear; clc; close all
addpath('..')
addpath('../borrowed code')
[X,Y,n] = aux_load('Visual','05');

param.L = 8; param.Fs = 512; param.NFFT = 1024; param.NSTEP = 2;

X = aux_chan(X,[5 24]);
X = aux_extr(X, 769:1024);
%X = aux_deci(X,2);
%X = aux_svd(X, 1);
X = aux_transform(X, 'spec', param);

for i = 1:length(X)
    X{i} = permute(X{i}, [2 3 1]);
end

size(X{1})

%save('C:\Users\Albin Heimerson\Desktop\exjobb\DATA\Modified\spectogram\X6.mat', 'X','-v7.3')
%save('C:\Users\Albin Heimerson\Desktop\exjobb\DATA\Modified\spectogram\Y6.mat', 'Y','-v7.3')

save('/lunarc/nobackup/users/albheim/EEG-klassificering/DATA/Modified/spectogram/U5.mat', 'X', 'Y', '-v7.3')
nvidia smi
Wed Apr 11 10:12:25 2018       
+------------------------------------------------------+                       
| NVIDIA-SMI 352.93     Driver Version: 384.81         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 0000:04:00.0     Off |                    0 |
| N/A   24C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 0000:05:00.0     Off |                    0 |
| N/A   29C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 0000:84:00.0     Off |                    0 |
| N/A   23C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 0000:85:00.0     Off |                    0 |
| N/A   30C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
start time
Wed Apr 11 10:12:25 CEST 2018
DATA
2.4G	/local/slurmtmp.605371/DATA/Visual
2.4G	/local/slurmtmp.605371/DATA/Verbal
388M	/local/slurmtmp.605371/DATA/Modified/marginal
3.0G	/local/slurmtmp.605371/DATA/Modified/spectogram
3.3G	/local/slurmtmp.605371/DATA/Modified
8.0G	/local/slurmtmp.605371/DATA
copy done time
Wed Apr 11 10:12:38 CEST 2018

                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017b (9.3.0.713579) 64-bit (glnxa64)
                             September 14, 2017

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

ans =

   128   512     2

>> 2018-04-11 10:13:11.398418: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-11 10:13:11.786973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:04:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-11 10:13:12.039354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 1 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:05:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-11 10:13:12.296222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 2 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:84:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-11 10:13:12.531475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 3 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:85:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-11 10:13:12.532130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Device peer to peer matrix
2018-04-11 10:13:12.532236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1051] DMA: 0 1 2 3 
2018-04-11 10:13:12.532261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 0:   Y Y N N 
2018-04-11 10:13:12.532276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 1:   Y Y N N 
2018-04-11 10:13:12.532291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 2:   N N Y Y 
2018-04-11 10:13:12.532306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1061] 3:   N N Y Y 
2018-04-11 10:13:12.532334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-11 10:13:12.532353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-04-11 10:13:12.532370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-04-11 10:13:12.532386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:85:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 10115637548944199782
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11324823962
locality {
  bus_id: 1
}
incarnation: 8703088266569730216
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7"
, name: "/device:GPU:1"
device_type: "GPU"
memory_limit: 11322769408
locality {
  bus_id: 1
}
incarnation: 16244796070905441452
physical_device_desc: "device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7"
, name: "/device:GPU:2"
device_type: "GPU"
memory_limit: 11324823962
locality {
  bus_id: 2
}
incarnation: 9489118152776663544
physical_device_desc: "device: 2, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7"
, name: "/device:GPU:3"
device_type: "GPU"
memory_limit: 11322831668
locality {
  bus_id: 2
}
incarnation: 9473019617266538888
physical_device_desc: "device: 3, name: Tesla K80, pci bus id: 0000:85:00.0, compute capability: 3.7"
]
/local/slurmtmp.605371/DATA/Modified/spectogram/U5.mat
(1, 187)
(1, 187)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(2, 512, 128)
(187, 2, 512, 128)
(187, 2, 512, 1, 128)
(2, 512, 1, 128)
Traceback (most recent call last):
  File "conv2d_spect.py", line 36, in <module>
    m_t = Conv2D(4, (8, 8), padding='same')(m_in)
  File "/home/albheim/.conda/envs/test/lib/python3.6/site-packages/keras/engine/topology.py", line 575, in __call__
    self.assert_input_compatibility(inputs)
  File "/home/albheim/.conda/envs/test/lib/python3.6/site-packages/keras/engine/topology.py", line 474, in assert_input_compatibility
    str(K.ndim(x)))
ValueError: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=5
end time
Wed Apr 11 10:13:16 CEST 2018
