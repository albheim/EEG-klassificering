data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J tdiff5f
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="time_diff.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

cp -r "${DATA_DIR}/DATA" $SNIC_TMP
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import TimeDistributed, Lambda, AlphaDropout
from keras.layers import SimpleRNN, RNN, LSTM, GRU
from keras.layers import Conv1D, MaxPooling1D, Flatten
from keras.layers import ELU, PReLU, Activation, AveragePooling1D

from keras.optimizers import SGD, Adam, RMSprop, Nadam
from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util

# import data
x, y = data.load_single(cut=False, visual=True, transpose=True)
xt, yt = data.load_single(cut=False, visual=True, study=False, transpose=True)
print(x[0].shape, xt[0].shape)


#settings
splits = 5
n_subs = len(x)
n_models = 1
bin_size = 40
n_bins = 6
p_size = bin_size * n_bins

train_start = 768
train_end = 1536
train_last = train_end - p_size
train_tp = range(train_start, train_last, bin_size)
train_steps = len(train_tp)

pred_start = 512
pred_end = 2048
pred_last = pred_end - p_size
pred_tp = range(pred_start, pred_last, bin_size)
pred_steps = len(pred_tp)

heatmap = np.zeros((pred_steps, pred_steps))


# create net
m_in = Input(shape=(p_size, 31))
m_noise = GaussianNoise(np.std(x[0][0] / 100))(m_in) # how much noice to have????

m_t = Conv1D(30, 64, padding='causal')(m_noise)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.2)(m_t)

m_t = Conv1D(15, 32, padding='causal')(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.3)(m_t)

m_t = Conv1D(10, 16, padding='causal')(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.4)(m_t)

m_t = Flatten()(m_t)
# m_t = Dense(35)(m_t)
# m_t = BatchNormalization()(m_t)
# m_t = Activation('tanh')(m_t)
m_t = Dense(15)(m_t)
m_t = BatchNormalization()(m_t)
m_t = Activation('tanh')(m_t)
m_out = Dense(3, activation='softmax')(m_t)

model = Model(inputs=m_in, outputs=m_out)

m_save = model.get_config()
model.summary()


# train
for j in range(n_models):
    avgacc = 0
    for i in range(n_subs):
        n = x[i].shape[0]
        acc = 0
        for tr, val in util.kfold(n, splits, shuffle=True):
            # recreate model
            model = Model.from_config(m_save)
            model.compile(loss='categorical_crossentropy',
                          optimizer='adam',
                          metrics=['accuracy'])

            # fit with next kfold data
            xtr = x[i][tr]
            ytr = y[i][tr]
            xva = x[i][val]
            yva = y[i][val]
            xte = xt[i]
            yte = yt[i]
            for k in range(10):
                for t in train_tp:
                    model.fit(xtr[:, t:t+p_size], ytr,
                              batch_size=8, epochs=2, verbose=0)

            a1 = []
            a2 = []
            for t in pred_tp:
                _, a = model.evaluate(xva[:, t:t+p_size], yva, verbose=0)
                a1.append(a)
                _, a = model.evaluate(xte[:, t:t+p_size], yte, verbose=0)
                a2.append(a)

            # do a1/a2 avg over subject before jultiply?
            a1 = np.array(a1).reshape((len(a1), 1))
            a2 = np.array(a2).reshape((len(a2), 1))
            heatmap += a1 * a2.T

            acc += np.max(a1)

        K.clear_session()

        acc /= splits
        print("subject {} avg of max acc over {} splits {}".format(i, splits, acc))
        avgacc += acc

    avgacc /= n_subs
    print("avg over subjects", avgacc)

print(heatmap)
np.savetxt("heatmap.txt", heatmap, delimiter=',')


nvidia smi
Mon Apr  9 18:10:35 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   25C    P8    27W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   31C    P8    31W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   25C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   31C    P8    29W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
start time
Mon Apr  9 18:10:35 CEST 2018
DATA
2.4G	/local/slurmtmp.599730/DATA/Visual
2.4G	/local/slurmtmp.599730/DATA/Verbal
388M	/local/slurmtmp.599730/DATA/Modified/marginal
2.7G	/local/slurmtmp.599730/DATA/Modified/spectogram
3.1G	/local/slurmtmp.599730/DATA/Modified
7.8G	/local/slurmtmp.599730/DATA
copy done time
Mon Apr  9 18:12:53 CEST 2018
2018-04-09 18:12:59.593570: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-09 18:13:00.145746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:04:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-09 18:13:00.145871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 18:14:52.597417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 18:24:15.654839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 18:33:44.532668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 18:43:11.130150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 18:52:35.357328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:02:08.243345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:11:34.088193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:21:23.867591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:31:14.651243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:40:38.046734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:49:55.344171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 19:59:35.216831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:09:16.505958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:18:56.727858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:28:13.900497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:37:53.223147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:47:32.868740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-04-09 20:56:48.381213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5428561824066156642
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11324823962
locality {
  bus_id: 1
}
incarnation: 16191770350911261677
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7"
]
loading:  Subj01_CleanData_study_FA
loading:  Subj01_CleanData_study_LM
loading:  Subj01_CleanData_study_OB
loading:  Subj02_CleanData_study_FA
loading:  Subj02_CleanData_study_LM
loading:  Subj02_CleanData_study_OB
loading:  Subj03_CleanData_study_FA
loading:  Subj03_CleanData_study_LM
loading:  Subj03_CleanData_study_OB
loading:  Subj04_CleanData_study_FA
loading:  Subj04_CleanData_study_LM
loading:  Subj04_CleanData_study_OB
loading:  Subj05_CleanData_study_FA
loading:  Subj05_CleanData_study_LM
loading:  Subj05_CleanData_study_OB
loading:  Subj06_CleanData_study_FA
loading:  Subj06_CleanData_study_LM
loading:  Subj06_CleanData_study_OB
loading:  Subj07_CleanData_study_FA
loading:  Subj07_CleanData_study_LM
loading:  Subj07_CleanData_study_OB
loading:  Subj08_CleanData_study_FA
loading:  Subj08_CleanData_study_LM
loading:  Subj08_CleanData_study_OB
loading:  Subj09_CleanData_study_FA
loading:  Subj09_CleanData_study_LM
loading:  Subj09_CleanData_study_OB
loading:  Subj11_CleanData_study_FA
loading:  Subj11_CleanData_study_LM
loading:  Subj11_CleanData_study_OB
loading:  Subj12_CleanData_study_FA
loading:  Subj12_CleanData_study_LM
loading:  Subj12_CleanData_study_OB
loading:  Subj13_CleanData_study_FA
loading:  Subj13_CleanData_study_LM
loading:  Subj13_CleanData_study_OB
loading:  Subj14_CleanData_study_FA
loading:  Subj14_CleanData_study_LM
loading:  Subj14_CleanData_study_OB
loading:  Subj15_CleanData_study_FA
loading:  Subj15_CleanData_study_LM
loading:  Subj15_CleanData_study_OB
loading:  Subj16_CleanData_study_FA
loading:  Subj16_CleanData_study_LM
loading:  Subj16_CleanData_study_OB
loading:  Subj17_CleanData_study_FA
loading:  Subj17_CleanData_study_LM
loading:  Subj17_CleanData_study_OB
loading:  Subj18_CleanData_study_FA
loading:  Subj18_CleanData_study_LM
loading:  Subj18_CleanData_study_OB
loading:  Subj19_CleanData_study_FA
loading:  Subj19_CleanData_study_LM
loading:  Subj19_CleanData_study_OB
loading:  Subj01_CleanData_test_FA_visual
loading:  Subj01_CleanData_test_LM_visual
loading:  Subj01_CleanData_test_OB_visual
loading:  Subj02_CleanData_test_FA_visual
loading:  Subj02_CleanData_test_LM_visual
loading:  Subj02_CleanData_test_OB_visual
loading:  Subj03_CleanData_test_FA_visual
loading:  Subj03_CleanData_test_LM_visual
loading:  Subj03_CleanData_test_OB_visual
loading:  Subj04_CleanData_test_FA_visual
loading:  Subj04_CleanData_test_LM_visual
loading:  Subj04_CleanData_test_OB_visual
loading:  Subj05_CleanData_test_FA_visual
loading:  Subj05_CleanData_test_LM_visual
loading:  Subj05_CleanData_test_OB_visual
loading:  Subj06_CleanData_test_FA_visual
loading:  Subj06_CleanData_test_LM_visual
loading:  Subj06_CleanData_test_OB_visual
loading:  Subj07_CleanData_test_FA_visual
loading:  Subj07_CleanData_test_LM_visual
loading:  Subj07_CleanData_test_OB_visual
loading:  Subj08_CleanData_test_FA_visual
loading:  Subj08_CleanData_test_LM_visual
loading:  Subj08_CleanData_test_OB_visual
loading:  Subj09_CleanData_test_FA_visual
loading:  Subj09_CleanData_test_LM_visual
loading:  Subj09_CleanData_test_OB_visual
loading:  Subj11_CleanData_test_FA_visual
loading:  Subj11_CleanData_test_LM_visual
loading:  Subj11_CleanData_test_OB_visual
loading:  Subj12_CleanData_test_FA_visual
loading:  Subj12_CleanData_test_LM_visual
loading:  Subj12_CleanData_test_OB_visual
loading:  Subj13_CleanData_test_FA_visual
loading:  Subj13_CleanData_test_LM_visual
loading:  Subj13_CleanData_test_OB_visual
loading:  Subj14_CleanData_test_FA_visual
loading:  Subj14_CleanData_test_LM_visual
loading:  Subj14_CleanData_test_OB_visual
loading:  Subj15_CleanData_test_FA_visual
loading:  Subj15_CleanData_test_LM_visual
loading:  Subj15_CleanData_test_OB_visual
loading:  Subj16_CleanData_test_FA_visual
loading:  Subj16_CleanData_test_LM_visual
loading:  Subj16_CleanData_test_OB_visual
loading:  Subj17_CleanData_test_FA_visual
loading:  Subj17_CleanData_test_LM_visual
loading:  Subj17_CleanData_test_OB_visual
loading:  Subj18_CleanData_test_FA_visual
loading:  Subj18_CleanData_test_LM_visual
loading:  Subj18_CleanData_test_OB_visual
loading:  Subj19_CleanData_test_FA_visual
loading:  Subj19_CleanData_test_LM_visual
loading:  Subj19_CleanData_test_OB_visual
(185, 2049, 31) (90, 2049, 31)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 240, 31)           0         
_________________________________________________________________
gaussian_noise_1 (GaussianNo (None, 240, 31)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 240, 30)           59550     
_________________________________________________________________
batch_normalization_1 (Batch (None, 240, 30)           120       
_________________________________________________________________
elu_1 (ELU)                  (None, 240, 30)           0         
_________________________________________________________________
average_pooling1d_1 (Average (None, 120, 30)           0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 120, 30)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 120, 15)           14415     
_________________________________________________________________
batch_normalization_2 (Batch (None, 120, 15)           60        
_________________________________________________________________
elu_2 (ELU)                  (None, 120, 15)           0         
_________________________________________________________________
average_pooling1d_2 (Average (None, 60, 15)            0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 60, 15)            0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 60, 10)            2410      
_________________________________________________________________
batch_normalization_3 (Batch (None, 60, 10)            40        
_________________________________________________________________
elu_3 (ELU)                  (None, 60, 10)            0         
_________________________________________________________________
average_pooling1d_3 (Average (None, 30, 10)            0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 30, 10)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 300)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                4515      
_________________________________________________________________
batch_normalization_4 (Batch (None, 15)                60        
_________________________________________________________________
activation_1 (Activation)    (None, 15)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 48        
=================================================================
Total params: 81,218
Trainable params: 81,078
Non-trainable params: 140
_________________________________________________________________
subject 0 avg of max acc over 10 splits 0.6760233879089356
subject 1 avg of max acc over 10 splits 0.6842105329036713
subject 2 avg of max acc over 10 splits 0.8064327538013458
subject 3 avg of max acc over 10 splits 0.7669590592384339
subject 4 avg of max acc over 10 splits 0.7380117058753968
subject 5 avg of max acc over 10 splits 0.6795321583747864
subject 6 avg of max acc over 10 splits 0.7081871271133423
subject 7 avg of max acc over 10 splits 0.6736842155456543
subject 8 avg of max acc over 10 splits 0.833625727891922
subject 9 avg of max acc over 10 splits 0.7195906519889832
subject 10 avg of max acc over 10 splits 0.7421052634716034
subject 11 avg of max acc over 10 splits 0.6859649062156677
subject 12 avg of max acc over 10 splits 0.7071052610874176
subject 13 avg of max acc over 10 splits 0.7792397618293763
subject 14 avg of max acc over 10 splits 0.6765789449214935
subject 15 avg of max acc over 10 splits 0.7578947424888611
subject 16 avg of max acc over 10 splits 0.615204679965973
subject 17 avg of max acc over 10 splits 0.7461988389492035
avg over subjects 0.722030539976226
[[12.34757174 12.23980004 12.25747711 ... 12.23728309 12.39486166
  12.26608865]
 [12.41403829 12.28054085 12.36330236 ... 12.35049319 12.51222928
  12.43409905]
 [12.6449517  12.53902388 12.58147287 ... 12.56881128 12.70819152
  12.65502627]
 ...
 [29.23440499 29.09715589 29.40791482 ... 30.27120005 30.70577372
  30.49353407]
 [29.04705888 28.83501579 29.23852541 ... 30.09134273 30.49609728
  30.27295798]
 [28.24459966 28.0479707  28.38347578 ... 29.28451177 29.65174146
  29.42589563]]
end time
Mon Apr  9 21:06:05 CEST 2018
slurmstepd: error: Exceeded step memory limit at some point.
