data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J bestall
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="best_all.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

cp -r "${DATA_DIR}/DATA" $SNIC_TMP
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import TimeDistributed, Lambda, AlphaDropout
from keras.layers import SimpleRNN, RNN, LSTM, GRU
from keras.layers import Conv1D, MaxPooling1D, Flatten
from keras.layers import ELU, PReLU, Activation, AveragePooling1D

from keras.optimizers import SGD, Adam, RMSprop, Nadam
from keras import regularizers as rg
from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_all(cut=True, visual=True, study=True, transpose=True)
xt, yt = data.load_all(cut=True, visual=True, study=False, transpose=True)
print(x[0].shape, xt[0].shape)

splits = 10

def offset_slice(inputs):
    w = 630
    r = np.random.randint(inputs.shape[1] - w + 1)
    return inputs[:, r:r + w, :]


m_in = Input(shape=x[0].shape)
m_off = Lambda(offset_slice)(m_in)
m_noise = GaussianNoise(np.std(x[0] / 100))(m_off) # how much noice to have????

m_t = Conv1D(30, 64, padding='causal', kernel_regularizer=rg.l1(0.01))(m_noise)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.2)(m_t)

m_t = Conv1D(15, 32, padding='causal', kernel_regularizer=rg.l1(0.01))(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.3)(m_t)

m_t = Conv1D(10, 16, padding='causal', kernel_regularizer=rg.l1(0.01))(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling1D(2)(m_t)
m_t = Dropout(0.4)(m_t)

m_t = Flatten()(m_t)
# m_t = Dense(35)(m_t)
# m_t = BatchNormalization()(m_t)
# m_t = Activation('tanh')(m_t)
m_t = Dense(15, kernel_regularizer=rg.l1(0.01))(m_t)
m_t = BatchNormalization()(m_t)
m_t = Activation('tanh')(m_t)
m_out = Dense(3, activation='softmax')(m_t)

model = Model(inputs=m_in, outputs=m_out)

m_save = model.get_config()
model.summary()

n = x.shape[0]
acc = 0
acc2 = 0
for tr, val in util.kfold(n, splits, shuffle=True):
    # recreate model
    model = Model.from_config(m_save)
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])

    # fit with next kfold data
    h = model.fit(x[tr], y[tr],
                  # validation_data=(x[i][val], y[i][val]),
                  batch_size=64, epochs=200, verbose=0)

    _, a = model.evaluate(x[val], y[val], verbose=0)
    _, a2 = model.evaluate(xt, yt, verbose=0)
    acc += a
    acc2 += a2

K.clear_session()

acc /= splits
acc2 /= splits

print("avg accuracy {}/{} over {} splits".format(acc, acc2, splits))
nvidia smi
Fri Apr 13 10:18:56 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   57C    P0    80W / 149W |  10974MiB / 11439MiB |      8%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   54C    P8    33W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   25C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   32C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0    147807      C   python                                     10961MiB |
+-----------------------------------------------------------------------------+
start time
Fri Apr 13 10:18:56 CEST 2018
DATA
2.4G	/local/slurmtmp.611061/DATA/Visual
2.4G	/local/slurmtmp.611061/DATA/Verbal
388M	/local/slurmtmp.611061/DATA/Modified/marginal
16G	/local/slurmtmp.611061/DATA/Modified/spectogram
16G	/local/slurmtmp.611061/DATA/Modified
21G	/local/slurmtmp.611061/DATA
copy done time
Fri Apr 13 10:23:13 CEST 2018
2018-04-13 10:23:14.618131: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-13 10:23:14.680946: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED
2018-04-13 10:23:14.681040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: ag05
2018-04-13 10:23:14.681065: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: ag05
2018-04-13 10:23:14.681144: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 384.81.0
2018-04-13 10:23:14.681189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:369] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.81  Sat Sep  2 02:43:11 PDT 2017
GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC) 
"""
2018-04-13 10:23:14.681229: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 384.81.0
2018-04-13 10:23:14.681250: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 384.81.0
/var/spool/slurm/job611061/slurm_script: line 42: 182691 Killed                  python $PY_FILE $SNIC_TMP
end time
Fri Apr 13 10:25:46 CEST 2018
slurmstepd: error: Exceeded step memory limit at some point.
slurmstepd: error: Exceeded job memory limit at some point.
