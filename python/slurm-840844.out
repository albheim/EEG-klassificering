data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J eegnrev
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="eegnet.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

CURR_DIR="$(pwd)"
cd $DATA_DIR
cp -r --parents DATA/Visual $SNIC_TMP
cp -r --parents DATA/Verbal $SNIC_TMP
cd $CURR_DIR
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import util
import data

import numpy as np

from keras.models import Model
from keras.layers import Dense, Dropout, Input, BatchNormalization
from keras.layers import AveragePooling2D, SeparableConv2D, DepthwiseConv2D
from keras.layers import Conv2D, Flatten
from keras.layers import ELU, Reshape
from keras import regularizers

from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())


xt, yt = data.load_single(cut=True, visual=True, transpose=True)
x, y = data.load_single(cut=True, visual=True, study=False, transpose=True)
print(x[0].shape, xt[0].shape)

splits = 10
n_subs = len(x)
n_models = 5
msets = [None for j in range(n_models)]
accs = [0 for j in range(n_models)]
accs2 = [0 for j in range(n_models)]

# channels = [4, 23]
# for i in range(n_subs):
#     x[i] = x[i][:, :, channels]
#     xt[i] = xt[i][:, :, channels]


for j in range(n_models):

    T, C = x[0][0].shape
    N = 3
    samp_freq = 512

    F = 8

    m_in = Input(shape=(T, C))
    m_t = Reshape((T, C, 1))(m_in)

    m_t = Conv2D(F, (samp_freq // 2, 1), padding='same',
                 kernel_regularizer=regularizers.l1_l2(0.0001, 0.0001))(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = DepthwiseConv2D((1, C), depth_multiplier=1, padding='valid',
                          kernel_regularizer=regularizers.l1_l2(0.0001, 0.0001))(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = Dropout(0.25, noise_shape=(1, 1, F))(m_t)
    # print(m_t._keras_shape)

    m_t = SeparableConv2D(F, (8, 1), padding='same',
                          kernel_regularizer=regularizers.l1_l2(0.0001, 0.0001))(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = AveragePooling2D((4, 1))(m_t)
    m_t = Dropout(0.25, noise_shape=(1, 1, F))(m_t)

    m_t = SeparableConv2D(2 * F, (8, 1), padding='same',
                          kernel_regularizer=regularizers.l1_l2(0.0001, 0.0001))(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = AveragePooling2D((4, 1))(m_t)
    m_t = Dropout(0.25, noise_shape=(1, 1, 2 * F))(m_t)


    m_t = Flatten()(m_t)
    m_out = Dense(3, activation='softmax')(m_t)

    model = Model(inputs=m_in, outputs=m_out)

    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])

    if j == 0:
        model.summary()


    w_save = model.get_weights()
    avgacc = 0
    avgacc2 = 0
    for i in range(n_subs):
        n = x[i].shape[0]
        acc = 0
        acc2 = 0
        for tr, val in util.kfold(n, splits):
            # reset to initial weights
            model.set_weights(w_save)

            # fit with next kfold data
            h = model.fit(x[i][tr], y[i][tr],
                          #validation_data=(x[i][val], y[i][val]),
                          batch_size=64, epochs=500, verbose=0)

            _, a = model.evaluate(x[i][val], y[i][val], verbose=0)
            _, a2 = model.evaluate(xt[i], yt[i], verbose=0)

            acc += a
            acc2 += a2


        acc /= splits
        acc2 /= splits
        avgacc += acc
        avgacc2 += acc2

        print("subject {}, avg accuracy {}/{} over {} splits".format(i + 1 if i + 1 < 10 else i + 2,
                                                                     acc, acc2, splits))

    avgacc /= n_subs
    accs[j] = avgacc
    avgacc2 /= n_subs
    accs2[j] = avgacc2
    print("avg accuracy over all subjects {}/{}".format(avgacc, avgacc2))


for a, a2 in sorted(zip(accs, accs2)):
    print("acc {}/{}\n".format(a, a2))

print("avg over all trials and subjects {}/{}".format(sum(accs) / len(accs), sum(accs2) / len(accs2)))
nvidia smi
Tue May 29 16:40:35 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   22C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   28C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   23C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   28C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
start time
Tue May 29 16:40:35 CEST 2018
DATA
2.4G	/local/slurmtmp.840844/DATA/Visual
2.4G	/local/slurmtmp.840844/DATA/Verbal
4.7G	/local/slurmtmp.840844/DATA
copy done time
Tue May 29 16:42:02 CEST 2018
2018-05-29 16:42:13.271882: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-29 16:42:13.871783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:04:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-05-29 16:42:13.871879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
2018-05-29 16:42:31.276714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5790195766281675778
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11325135258
locality {
  bus_id: 1
}
incarnation: 7332291399722910117
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7"
]
loading:  Subj01_CleanData_study_FA
loading:  Subj01_CleanData_study_LM
loading:  Subj01_CleanData_study_OB
loading:  Subj02_CleanData_study_FA
loading:  Subj02_CleanData_study_LM
loading:  Subj02_CleanData_study_OB
loading:  Subj03_CleanData_study_FA
loading:  Subj03_CleanData_study_LM
loading:  Subj03_CleanData_study_OB
loading:  Subj04_CleanData_study_FA
loading:  Subj04_CleanData_study_LM
loading:  Subj04_CleanData_study_OB
loading:  Subj05_CleanData_study_FA
loading:  Subj05_CleanData_study_LM
loading:  Subj05_CleanData_study_OB
loading:  Subj06_CleanData_study_FA
loading:  Subj06_CleanData_study_LM
loading:  Subj06_CleanData_study_OB
loading:  Subj07_CleanData_study_FA
loading:  Subj07_CleanData_study_LM
loading:  Subj07_CleanData_study_OB
loading:  Subj08_CleanData_study_FA
loading:  Subj08_CleanData_study_LM
loading:  Subj08_CleanData_study_OB
loading:  Subj09_CleanData_study_FA
loading:  Subj09_CleanData_study_LM
loading:  Subj09_CleanData_study_OB
loading:  Subj11_CleanData_study_FA
loading:  Subj11_CleanData_study_LM
loading:  Subj11_CleanData_study_OB
loading:  Subj12_CleanData_study_FA
loading:  Subj12_CleanData_study_LM
loading:  Subj12_CleanData_study_OB
loading:  Subj13_CleanData_study_FA
loading:  Subj13_CleanData_study_LM
loading:  Subj13_CleanData_study_OB
loading:  Subj14_CleanData_study_FA
loading:  Subj14_CleanData_study_LM
loading:  Subj14_CleanData_study_OB
loading:  Subj15_CleanData_study_FA
loading:  Subj15_CleanData_study_LM
loading:  Subj15_CleanData_study_OB
loading:  Subj16_CleanData_study_FA
loading:  Subj16_CleanData_study_LM
loading:  Subj16_CleanData_study_OB
loading:  Subj17_CleanData_study_FA
loading:  Subj17_CleanData_study_LM
loading:  Subj17_CleanData_study_OB
loading:  Subj18_CleanData_study_FA
loading:  Subj18_CleanData_study_LM
loading:  Subj18_CleanData_study_OB
loading:  Subj19_CleanData_study_FA
loading:  Subj19_CleanData_study_LM
loading:  Subj19_CleanData_study_OB
loading:  Subj01_CleanData_test_FA_visual
loading:  Subj01_CleanData_test_LM_visual
loading:  Subj01_CleanData_test_OB_visual
loading:  Subj02_CleanData_test_FA_visual
loading:  Subj02_CleanData_test_LM_visual
loading:  Subj02_CleanData_test_OB_visual
loading:  Subj03_CleanData_test_FA_visual
loading:  Subj03_CleanData_test_LM_visual
loading:  Subj03_CleanData_test_OB_visual
loading:  Subj04_CleanData_test_FA_visual
loading:  Subj04_CleanData_test_LM_visual
loading:  Subj04_CleanData_test_OB_visual
loading:  Subj05_CleanData_test_FA_visual
loading:  Subj05_CleanData_test_LM_visual
loading:  Subj05_CleanData_test_OB_visual
loading:  Subj06_CleanData_test_FA_visual
loading:  Subj06_CleanData_test_LM_visual
loading:  Subj06_CleanData_test_OB_visual
loading:  Subj07_CleanData_test_FA_visual
loading:  Subj07_CleanData_test_LM_visual
loading:  Subj07_CleanData_test_OB_visual
loading:  Subj08_CleanData_test_FA_visual
loading:  Subj08_CleanData_test_LM_visual
loading:  Subj08_CleanData_test_OB_visual
loading:  Subj09_CleanData_test_FA_visual
loading:  Subj09_CleanData_test_LM_visual
loading:  Subj09_CleanData_test_OB_visual
loading:  Subj11_CleanData_test_FA_visual
loading:  Subj11_CleanData_test_LM_visual
loading:  Subj11_CleanData_test_OB_visual
loading:  Subj12_CleanData_test_FA_visual
loading:  Subj12_CleanData_test_LM_visual
loading:  Subj12_CleanData_test_OB_visual
loading:  Subj13_CleanData_test_FA_visual
loading:  Subj13_CleanData_test_LM_visual
loading:  Subj13_CleanData_test_OB_visual
loading:  Subj14_CleanData_test_FA_visual
loading:  Subj14_CleanData_test_LM_visual
loading:  Subj14_CleanData_test_OB_visual
loading:  Subj15_CleanData_test_FA_visual
loading:  Subj15_CleanData_test_LM_visual
loading:  Subj15_CleanData_test_OB_visual
loading:  Subj16_CleanData_test_FA_visual
loading:  Subj16_CleanData_test_LM_visual
loading:  Subj16_CleanData_test_OB_visual
loading:  Subj17_CleanData_test_FA_visual
loading:  Subj17_CleanData_test_LM_visual
loading:  Subj17_CleanData_test_OB_visual
loading:  Subj18_CleanData_test_FA_visual
loading:  Subj18_CleanData_test_LM_visual
loading:  Subj18_CleanData_test_OB_visual
loading:  Subj19_CleanData_test_FA_visual
loading:  Subj19_CleanData_test_LM_visual
loading:  Subj19_CleanData_test_OB_visual
(90, 768, 31) (185, 768, 31)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 768, 31)           0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 768, 31, 1)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 768, 31, 8)        2056      
_________________________________________________________________
batch_normalization_1 (Batch (None, 768, 31, 8)        32        
_________________________________________________________________
depthwise_conv2d_1 (Depthwis (None, 768, 1, 8)         256       
_________________________________________________________________
batch_normalization_2 (Batch (None, 768, 1, 8)         32        
_________________________________________________________________
elu_1 (ELU)                  (None, 768, 1, 8)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 768, 1, 8)         0         
_________________________________________________________________
separable_conv2d_1 (Separabl (None, 768, 1, 8)         136       
_________________________________________________________________
batch_normalization_3 (Batch (None, 768, 1, 8)         32        
_________________________________________________________________
elu_2 (ELU)                  (None, 768, 1, 8)         0         
_________________________________________________________________
average_pooling2d_1 (Average (None, 192, 1, 8)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 192, 1, 8)         0         
_________________________________________________________________
separable_conv2d_2 (Separabl (None, 192, 1, 16)        208       
_________________________________________________________________
batch_normalization_4 (Batch (None, 192, 1, 16)        64        
_________________________________________________________________
elu_3 (ELU)                  (None, 192, 1, 16)        0         
_________________________________________________________________
average_pooling2d_2 (Average (None, 48, 1, 16)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 48, 1, 16)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 768)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 2307      
=================================================================
Total params: 5,123
Trainable params: 5,043
Non-trainable params: 80
_________________________________________________________________
subject 1, avg accuracy 0.3444444514811039/0.30594594577679757 over 10 splits
subject 2, avg accuracy 0.31428572088479995/0.40267379632130024 over 10 splits
subject 3, avg accuracy 0.37692308723926543/0.35752688292213664 over 10 splits
subject 4, avg accuracy 0.33222223073244095/0.3762162153302013 over 10 splits
subject 5, avg accuracy 0.3645454652607441/0.34224598910559945 over 10 splits
subject 6, avg accuracy 0.33141025304794314/0.36249999974084934 over 10 splits
subject 7, avg accuracy 0.2861111156642437/0.3063829791038594 over 10 splits
subject 8, avg accuracy 0.3621212184429169/0.3163157905638218 over 10 splits
subject 9, avg accuracy 0.40833333432674407/0.2973118289984683 over 10 splits
subject 11, avg accuracy 0.33333333432674406/0.3335164841878545 over 10 splits
subject 12, avg accuracy 0.3655555613338947/0.35684210678464484 over 10 splits
subject 13, avg accuracy 0.32803031206130984/0.32872340504793407 over 10 splits
subject 14, avg accuracy 0.33214286118745806/0.4256544485766226 over 10 splits
subject 15, avg accuracy 0.35448718070983887/0.3436464095395573 over 10 splits
subject 16, avg accuracy 0.476190485060215/0.3338541666666667 over 10 splits
subject 17, avg accuracy 0.37857143878936766/0.34052631723253357 over 10 splits
subject 18, avg accuracy 0.3000000089406967/0.3286486490997108 over 10 splits
subject 19, avg accuracy 0.285555562376976/0.34861878550184366 over 10 splits
avg accuracy over all subjects 0.3485702012148168/0.3448416778055779
subject 1, avg accuracy 0.2888888940215111/0.2989189187980987 over 10 splits
subject 2, avg accuracy 0.4053571492433548/0.42352941198782484 over 10 splits
subject 3, avg accuracy 0.33846154659986494/0.3435483882984808 over 10 splits
subject 4, avg accuracy 0.28333333805203437/0.3724324319813702 over 10 splits
subject 5, avg accuracy 0.36636364459991455/0.3229946526295361 over 10 splits
subject 6, avg accuracy 0.2903846189379692/0.3250000000161969 over 10 splits
subject 7, avg accuracy 0.26666666865348815/0.3265957452356815 over 10 splits
subject 8, avg accuracy 0.3083333417773247/0.3357894752684392 over 10 splits
subject 9, avg accuracy 0.4416666716337204/0.33709677491457235 over 10 splits
subject 11, avg accuracy 0.3466666728258133/0.331318681711679 over 10 splits
subject 12, avg accuracy 0.2511111155152321/0.3210526328180966 over 10 splits
subject 13, avg accuracy 0.4356060653924942/0.3601063835494062 over 10 splits
subject 14, avg accuracy 0.40892857909202573/0.41884816557325 over 10 splits
subject 15, avg accuracy 0.36987179666757586/0.34475138246683784 over 10 splits
subject 16, avg accuracy 0.42142857760190966/0.33906250000000004 over 10 splits
subject 17, avg accuracy 0.3642857238650322/0.3831578955838555 over 10 splits
subject 18, avg accuracy 0.3285714417695999/0.327027027534472 over 10 splits
subject 19, avg accuracy 0.341111122071743/0.3453038684077026 over 10 splits
avg accuracy over all subjects 0.34761316490670047/0.34758524093197224
subject 1, avg accuracy 0.24444444850087166/0.278378377971617 over 10 splits
subject 2, avg accuracy 0.39821429550647736/0.45294117647058824 over 10 splits
subject 3, avg accuracy 0.4307692438364029/0.3688172054547135 over 10 splits
subject 4, avg accuracy 0.21111111491918563/0.39891891894308296 over 10 splits
subject 5, avg accuracy 0.34909091889858246/0.3561497323015795 over 10 splits
subject 6, avg accuracy 0.2576923094689846/0.3260869562625885 over 10 splits
subject 7, avg accuracy 0.2819444499909878/0.32925531924405005 over 10 splits
subject 8, avg accuracy 0.3727272793650627/0.34105263267692776 over 10 splits
subject 9, avg accuracy 0.34583333879709244/0.3182795709179294 over 10 splits
subject 11, avg accuracy 0.42222222983837127/0.329120879481127 over 10 splits
subject 12, avg accuracy 0.22888889387249947/0.34684210629839646 over 10 splits
subject 13, avg accuracy 0.3727272793650627/0.3398936175285502 over 10 splits
subject 14, avg accuracy 0.3339285746216774/0.4272251291112751 over 10 splits
subject 15, avg accuracy 0.3794871799647808/0.3436464095148592 over 10 splits
subject 16, avg accuracy 0.48571428954601287/0.35104166666666664 over 10 splits
subject 17, avg accuracy 0.31666667610406873/0.327894737845973 over 10 splits
subject 18, avg accuracy 0.3000000089406967/0.27081081070609997 over 10 splits
subject 19, avg accuracy 0.3066666714847088/0.30165746007011734 over 10 splits
avg accuracy over all subjects 0.3354516223900848/0.3448895948592301
subject 1, avg accuracy 0.3666666753590107/0.32324324314658703 over 10 splits
subject 2, avg accuracy 0.37500000447034837/0.42032085579028095 over 10 splits
subject 3, avg accuracy 0.36153846979141235/0.3467741947981619 over 10 splits
subject 4, avg accuracy 0.26888889595866206/0.3794594589842332 over 10 splits
subject 5, avg accuracy 0.29181819036602974/0.33903743337023073 over 10 splits
subject 6, avg accuracy 0.2980769269168377/0.32391304328389786 over 10 splits
subject 7, avg accuracy 0.2291666693985462/0.286702128008325 over 10 splits
subject 8, avg accuracy 0.34469697773456576/0.32105263303769266 over 10 splits
subject 9, avg accuracy 0.3694444477558136/0.31236559258353325 over 10 splits
subject 11, avg accuracy 0.21444444879889488/0.344505495094991 over 10 splits
subject 12, avg accuracy 0.2922222264111042/0.3078947380028273 over 10 splits
subject 13, avg accuracy 0.4083333432674408/0.3473404261343022 over 10 splits
subject 14, avg accuracy 0.41964286416769025/0.4115183228441558 over 10 splits
subject 15, avg accuracy 0.28333333432674407/0.31823204499746555 over 10 splits
subject 16, avg accuracy 0.4119047686457634/0.3416666666666667 over 10 splits
subject 17, avg accuracy 0.3880952447652817/0.30421052760199496 over 10 splits
subject 18, avg accuracy 0.3000000104308128/0.3070270268820427 over 10 splits
subject 19, avg accuracy 0.3488888993859291/0.3337016590721699 over 10 splits
avg accuracy over all subjects 0.3317867998861604/0.33716474946108665
subject 1, avg accuracy 0.24444444999098777/0.31189189155359526 over 10 splits
subject 2, avg accuracy 0.3785714343190193/0.4139037434669103 over 10 splits
subject 3, avg accuracy 0.32307693362236023/0.31182795760612336 over 10 splits
subject 4, avg accuracy 0.24888889491558075/0.35675675667620993 over 10 splits
subject 5, avg accuracy 0.32000000923871996/0.3625668452385275 over 10 splits
subject 6, avg accuracy 0.2967948704957962/0.3777173909156219 over 10 splits
subject 7, avg accuracy 0.36805556192994116/0.31702127781637174 over 10 splits
subject 8, avg accuracy 0.3719697058200836/0.3289473698327416 over 10 splits
subject 9, avg accuracy 0.34444445073604585/0.311827957894533 over 10 splits
subject 11, avg accuracy 0.3488888949155807/0.35274725327124967 over 10 splits
subject 12, avg accuracy 0.3111111156642437/0.33736842232315156 over 10 splits
subject 13, avg accuracy 0.39015152007341386/0.35957446871919835 over 10 splits
subject 14, avg accuracy 0.44642858058214185/0.43874345418670424 over 10 splits
subject 15, avg accuracy 0.3538461565971375/0.34806629903820335 over 10 splits
subject 16, avg accuracy 0.390476194024086/0.34010416666666665 over 10 splits
subject 17, avg accuracy 0.14523810148239136/0.31789473850476113 over 10 splits
subject 18, avg accuracy 0.3428571537137032/0.35135135172186666 over 10 splits
subject 19, avg accuracy 0.285555561631918/0.34972375774581127 over 10 splits
avg accuracy over all subjects 0.3283777549862863/0.3493352835099026
acc 0.3283777549862863/0.3493352835099026

acc 0.3317867998861604/0.33716474946108665

acc 0.3354516223900848/0.3448895948592301

acc 0.34761316490670047/0.34758524093197224

acc 0.3485702012148168/0.3448416778055779

avg over all trials and subjects 0.33835990867680976/0.3447633093135539
end time
Wed May 30 09:09:51 CEST 2018
