data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J bealltim
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="best.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

CURR_DIR="$(pwd)"
cd $DATA_DIR
cp -r --parents DATA/Visual $SNIC_TMP
cp -r --parents DATA/Verbal $SNIC_TMP
cd $CURR_DIR
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import TimeDistributed, Lambda, AlphaDropout
from keras.layers import SimpleRNN, RNN, LSTM, GRU
from keras.layers import Conv1D, MaxPooling1D, Flatten
from keras.layers import ELU, PReLU, Activation, AveragePooling1D

from keras.optimizers import SGD, Adam, RMSprop, Nadam
from keras import regularizers as rg
from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_single(cut=False, visual=False, transpose=True)
xt, yt = data.load_single(cut=False, visual=False, study=False, transpose=True)
    
print(x[0].shape, xt[0].shape)

splits = 10
n_subs = len(x)
n_models = 1
msets = [None for j in range(n_models)]
accs = [0 for j in range(n_models)]
accs2 = [0 for j in range(n_models)]
vals = np.zeros((31, ))

#channels = [25, 26, 29]
for i in range(n_subs):
    x[i] = x[i][:, ::4, :]
    xt[i] = xt[i][:, ::4, :]


def offset_slice(inputs):
    w = 630 // 5
    r = np.random.randint(inputs.shape[1] - w + 1)
    return inputs[:, r:r + w, :]

for j in range(n_models):

    msets[j] = " " # mset

    m_in = Input(shape=x[0][0].shape)
    m_off = Lambda(offset_slice)(m_in)
    m_noise = GaussianNoise(np.std(x[0][0] / 100))(m_off) # how much noice to have????

    m_t = Conv1D(30, 64, padding='causal')(m_in)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = AveragePooling1D(2)(m_t)
    m_t = Dropout(0.2)(m_t)

    m_t = Conv1D(15, 32, padding='causal')(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = AveragePooling1D(2)(m_t)
    m_t = Dropout(0.3)(m_t)

    m_t = Conv1D(10, 16, padding='causal')(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = ELU()(m_t)
    m_t = AveragePooling1D(2)(m_t)
    m_t = Dropout(0.4)(m_t)

    m_t = Flatten()(m_t)
    # m_t = Dense(35)(m_t)
    # m_t = BatchNormalization()(m_t)
    # m_t = Activation('tanh')(m_t)
    m_t = Dense(15)(m_t)
    m_t = BatchNormalization()(m_t)
    m_t = Activation('tanh')(m_t)
    m_out = Dense(3, activation='softmax')(m_t)

    model = Model(inputs=m_in, outputs=m_out)

    m_save = model.get_config()
    if j == 0:
        model.summary()

    avgacc = 0
    avgacc2 = 0
    for i in range(n_subs):
        xm = np.mean(x[i], axis=(0, 1))[np.newaxis, np.newaxis, :]
        xs = np.std(x[i], axis=(0, 1))[np.newaxis, np.newaxis, :]
        xi = (x[i] - xm) / xs
        xti = (xt[i] - xm) / xs
        
        n = x[i].shape[0]
        acc = 0
        acc2 = 0
        for tr, val in util.kfold(n, splits, shuffle=True):
            # recreate model
            model = Model.from_config(m_save)
            model.compile(loss='categorical_crossentropy',
                          optimizer='adam',
                          metrics=['accuracy'])
            # print(len(model.get_weights()))
            print(model.get_weights()[0].shape)

            # fit with next kfold data
            h = model.fit(xi[tr], y[i][tr],
                          # validation_data=(x[i][val], y[i][val]),
                          batch_size=64, epochs=200, verbose=0)
            h = h.history

            # vals += np.sum(np.absolute(model.get_weights()[0]), (0, 2))
            _, a = model.evaluate(xi[val], y[i][val], verbose=0)
            _, a2 = model.evaluate(xti, yt[i], verbose=0)
            acc += a
            acc2 += a2

        K.clear_session()

        acc /= splits
        acc2 /= splits
        avgacc += acc
        avgacc2 += acc2

        print("subject {}, avg accuracy {}/{} over {} splits".format(i + 1 if i + 1 < 10 else i + 2,
                                                                     acc, acc2, splits))

    avgacc /= n_subs
    accs[j] = avgacc
    avgacc2 /= n_subs
    accs2[j] = avgacc2
    print("avg accuracy over all subjects {}/{}".format(avgacc, avgacc2))

# print("channel values")
# for v in vals:
#     print(v / (n_models * n_subs * splits * 30 * 64))

for a, a2 in sorted(zip(accs, accs2)):
    print("acc {}/{}\n".format(a, a2))

print("avg over all trials and subjects {}/{}".format(sum(accs) / len(accs), sum(accs2) / len(accs2)))
nvidia smi
Tue May 22 15:43:37 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   44C    P0    86W / 149W |  10975MiB / 11441MiB |     49%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   44C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   24C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   31C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     60506      C   python                                     10962MiB |
+-----------------------------------------------------------------------------+
start time
Tue May 22 15:43:37 CEST 2018
DATA
2.4G	/local/slurmtmp.791789/DATA/Visual
2.4G	/local/slurmtmp.791789/DATA/Verbal
4.7G	/local/slurmtmp.791789/DATA
copy done time
Tue May 22 15:44:41 CEST 2018
2018-05-22 15:44:42.401863: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-22 15:44:42.599281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:05:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-05-22 15:44:42.599387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:45:01.739404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:47:46.262749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:50:37.366331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:53:28.865745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:56:20.538214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 15:59:13.229033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:02:07.358954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:04:56.254053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:07:52.287444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:10:45.644884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:13:38.779663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:16:31.510458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:19:22.807423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:22:17.575054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:25:13.703706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:28:03.560892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:30:59.393908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-05-22 16:33:52.682990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 11749468409724912201
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11325135258
locality {
  bus_id: 1
}
incarnation: 1208058822782111151
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7"
]
loading:  Subj01_CleanData_study_FA
loading:  Subj01_CleanData_study_LM
loading:  Subj01_CleanData_study_OB
loading:  Subj02_CleanData_study_FA
loading:  Subj02_CleanData_study_LM
loading:  Subj02_CleanData_study_OB
loading:  Subj06_CleanData_study_FA
loading:  Subj06_CleanData_study_LM
loading:  Subj06_CleanData_study_OB
loading:  Subj07_CleanData_study_FA
loading:  Subj07_CleanData_study_LM
loading:  Subj07_CleanData_study_OB
loading:  Subj08_CleanData_study_FA
loading:  Subj08_CleanData_study_LM
loading:  Subj08_CleanData_study_OB
loading:  Subj09_CleanData_study_FA
loading:  Subj09_CleanData_study_LM
loading:  Subj09_CleanData_study_OB
loading:  Subj10_CleanData_study_FA
loading:  Subj10_CleanData_study_LM
loading:  Subj10_CleanData_study_OB
loading:  Subj11_CleanData_study_FA
loading:  Subj11_CleanData_study_LM
loading:  Subj11_CleanData_study_OB
loading:  Subj12_CleanData_study_FA
loading:  Subj12_CleanData_study_LM
loading:  Subj12_CleanData_study_OB
loading:  Subj14_CleanData_study_FA
loading:  Subj14_CleanData_study_LM
loading:  Subj14_CleanData_study_OB
loading:  Subj15_CleanData_study_FA
loading:  Subj15_CleanData_study_LM
loading:  Subj15_CleanData_study_OB
loading:  Subj16_CleanData_study_FA
loading:  Subj16_CleanData_study_LM
loading:  Subj16_CleanData_study_OB
loading:  Subj17_CleanData_study_FA
loading:  Subj17_CleanData_study_LM
loading:  Subj17_CleanData_study_OB
loading:  Subj18_CleanData_study_FA
loading:  Subj18_CleanData_study_LM
loading:  Subj18_CleanData_study_OB
loading:  Subj19_CleanData_study_FA
loading:  Subj19_CleanData_study_LM
loading:  Subj19_CleanData_study_OB
loading:  Subj20_CleanData_study_FA
loading:  Subj20_CleanData_study_LM
loading:  Subj20_CleanData_study_OB
loading:  Subj21_CleanData_study_FA
loading:  Subj21_CleanData_study_LM
loading:  Subj21_CleanData_study_OB
loading:  Subj22_CleanData_study_FA
loading:  Subj22_CleanData_study_LM
loading:  Subj22_CleanData_study_OB
loading:  Subj01_CleanData_test_FA_lexical
loading:  Subj01_CleanData_test_LM_lexical
loading:  Subj01_CleanData_test_OB_lexical
loading:  Subj02_CleanData_test_FA_lexical
loading:  Subj02_CleanData_test_LM_lexical
loading:  Subj02_CleanData_test_OB_lexical
loading:  Subj06_CleanData_test_FA_lexical
loading:  Subj06_CleanData_test_LM_lexical
loading:  Subj06_CleanData_test_OB_lexical
loading:  Subj07_CleanData_test_FA_lexical
loading:  Subj07_CleanData_test_LM_lexical
loading:  Subj07_CleanData_test_OB_lexical
loading:  Subj08_CleanData_test_FA_lexical
loading:  Subj08_CleanData_test_LM_lexical
loading:  Subj08_CleanData_test_OB_lexical
loading:  Subj09_CleanData_test_FA_lexical
loading:  Subj09_CleanData_test_LM_lexical
loading:  Subj09_CleanData_test_OB_lexical
loading:  Subj10_CleanData_test_FA_lexical
loading:  Subj10_CleanData_test_LM_lexical
loading:  Subj10_CleanData_test_OB_lexical
loading:  Subj11_CleanData_test_FA_lexical
loading:  Subj11_CleanData_test_LM_lexical
loading:  Subj11_CleanData_test_OB_lexical
loading:  Subj12_CleanData_test_FA_lexical
loading:  Subj12_CleanData_test_LM_lexical
loading:  Subj12_CleanData_test_OB_lexical
loading:  Subj14_CleanData_test_FA_lexical
loading:  Subj14_CleanData_test_LM_lexical
loading:  Subj14_CleanData_test_OB_lexical
loading:  Subj15_CleanData_test_FA_lexical
loading:  Subj15_CleanData_test_LM_lexical
loading:  Subj15_CleanData_test_OB_lexical
loading:  Subj16_CleanData_test_FA_lexical
loading:  Subj16_CleanData_test_LM_lexical
loading:  Subj16_CleanData_test_OB_lexical
loading:  Subj17_CleanData_test_FA_lexical
loading:  Subj17_CleanData_test_LM_lexical
loading:  Subj17_CleanData_test_OB_lexical
loading:  Subj18_CleanData_test_FA_lexical
loading:  Subj18_CleanData_test_LM_lexical
loading:  Subj18_CleanData_test_OB_lexical
loading:  Subj19_CleanData_test_FA_lexical
loading:  Subj19_CleanData_test_LM_lexical
loading:  Subj19_CleanData_test_OB_lexical
loading:  Subj20_CleanData_test_FA_lexical
loading:  Subj20_CleanData_test_LM_lexical
loading:  Subj20_CleanData_test_OB_lexical
loading:  Subj21_CleanData_test_FA_lexical
loading:  Subj21_CleanData_test_LM_lexical
loading:  Subj21_CleanData_test_OB_lexical
loading:  Subj22_CleanData_test_FA_lexical
loading:  Subj22_CleanData_test_LM_lexical
loading:  Subj22_CleanData_test_OB_lexical
(175, 2049, 31) (90, 2049, 31)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 513, 31)           0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 513, 30)           59550     
_________________________________________________________________
batch_normalization_1 (Batch (None, 513, 30)           120       
_________________________________________________________________
elu_1 (ELU)                  (None, 513, 30)           0         
_________________________________________________________________
average_pooling1d_1 (Average (None, 256, 30)           0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 256, 30)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 256, 15)           14415     
_________________________________________________________________
batch_normalization_2 (Batch (None, 256, 15)           60        
_________________________________________________________________
elu_2 (ELU)                  (None, 256, 15)           0         
_________________________________________________________________
average_pooling1d_2 (Average (None, 128, 15)           0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 128, 15)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 128, 10)           2410      
_________________________________________________________________
batch_normalization_3 (Batch (None, 128, 10)           40        
_________________________________________________________________
elu_3 (ELU)                  (None, 128, 10)           0         
_________________________________________________________________
average_pooling1d_3 (Average (None, 64, 10)            0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 64, 10)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 640)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                9615      
_________________________________________________________________
batch_normalization_4 (Batch (None, 15)                60        
_________________________________________________________________
activation_1 (Activation)    (None, 15)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 48        
=================================================================
Total params: 86,318
Trainable params: 86,178
Non-trainable params: 140
_________________________________________________________________
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 1, avg accuracy 0.5529411941766739/0.3822222241097027 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 2, avg accuracy 0.6999999940395355/0.35625 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 3, avg accuracy 0.616959074139595/0.29047619189534873 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 4, avg accuracy 0.7365497052669525/0.3364485992727993 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 5, avg accuracy 0.7736842155456543/0.33472222222222225 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 6, avg accuracy 0.8456140339374543/0.3588235295091579 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 7, avg accuracy 0.8264705836772919/0.3481751829875212 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 8, avg accuracy 0.7807894825935364/0.4264705882352941 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 9, avg accuracy 0.698245620727539/0.318367347303702 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 11, avg accuracy 0.8997076034545899/0.34339622690711386 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 12, avg accuracy 0.7254386007785797/0.38536585377968424 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 13, avg accuracy 0.7134502947330474/0.3819148960899799 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 14, avg accuracy 0.8187134504318238/0.3329896907216495 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 15, avg accuracy 0.8028947353363037/0.3194444444444445 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 16, avg accuracy 0.8745613932609558/0.36862745144787956 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 17, avg accuracy 0.8181578993797303/0.30652174016703737 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 18, avg accuracy 0.7970760226249695/0.3461538460228469 over 10 splits
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
(64, 31, 30)
subject 19, avg accuracy 0.7963158011436462/0.3438095247603598 over 10 splits
avg accuracy over all subjects 0.7654205391804376/0.3488988644375969
acc 0.7654205391804376/0.3488988644375969

avg over all trials and subjects 0.7654205391804376/0.3488988644375969
end time
Tue May 22 16:36:51 CEST 2018
