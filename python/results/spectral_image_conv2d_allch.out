data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J allchBN
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="conv2d_spect.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

cp -r "${DATA_DIR}/DATA" $SNIC_TMP
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

matlab -nodisplay -nosplash -nodesktop -r "run('../matlab/save transformed/savetf.m');"
python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import Lambda
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import ELU, Activation, Flatten

from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_spect()

print(x.shape)

splits = 5

# channels = [4, 23]
# for i in range(n_subs):
#     x[i] = x[i][:, :, channels]
#     xt[i] = xt[i][:, :, channels]


m_in = Input(shape=x[0].shape)

m_t = Conv2D(4, (8, 16), padding='same')(m_in)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 16))(m_t)
m_t = Dropout(0.2)(m_t)

m_t = Conv2D(8, (8, 16), padding='same')(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 8))(m_t)
m_t = Dropout(0.3)(m_t)

m_t = Conv2D(16, (4, 8), padding='same')(m_t)
m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 8))(m_t)
m_t = Dropout(0.4)(m_t)

m_t = Flatten()(m_t)
m_t = Dense(15)(m_t)
m_t = BatchNormalization()(m_t)
m_t = Activation('tanh')(m_t)
m_out = Dense(3, activation='softmax')(m_t)

model = Model(inputs=m_in, outputs=m_out)

m_save = model.get_config()
model.summary()

acc = 0
for tr, val in util.kfold(len(x), splits, shuffle=True):

    model = Model.from_config(m_save)
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    # fit with next kfold data
    h = model.fit(x[tr], y[tr],
                  #validation_data=(x[val], y[val]),
                  batch_size=16, epochs=50, verbose=0)

    _, a = model.evaluate(x[val], y[val], verbose=0)
    acc += a

acc /= splits

print("avg accuracy {} over {} splits".format(acc, splits))
nvidia smi
Sat Apr  7 16:58:35 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   45C    P0    89W / 149W |  10974MiB / 11439MiB |     56%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   45C    P8    32W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   25C    P8    25W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   31C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     22870      C   python                                     10961MiB |
+-----------------------------------------------------------------------------+
start time
Sat Apr  7 16:58:35 CEST 2018
DATA
2.4G	/local/slurmtmp.587606/DATA/Visual
2.4G	/local/slurmtmp.587606/DATA/Verbal
388M	/local/slurmtmp.587606/DATA/Modified/marginal
2.7G	/local/slurmtmp.587606/DATA/Modified/spectogram
3.1G	/local/slurmtmp.587606/DATA/Modified
7.8G	/local/slurmtmp.587606/DATA
copy done time
Sat Apr  7 16:58:40 CEST 2018

                            < M A T L A B (R) >
                  Copyright 1984-2017 The MathWorks, Inc.
                   R2017b (9.3.0.713579) 64-bit (glnxa64)
                             September 14, 2017

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

ans =

          32        2048          31

>> 2018-04-07 17:01:27.757778: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-04-07 17:01:28.071766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:05:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-04-07 17:01:28.071860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
2018-04-07 17:01:50.785723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 3879289811138523326
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11324823962
locality {
  bus_id: 1
}
incarnation: 18023805052242069668
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7"
]
(1, 184)
184
(1, 184)
(184, 32, 2048, 31)
(32, 2048, 31)
(184, 32, 2048, 31)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 32, 2048, 31)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 32, 2048, 4)       15876     
_________________________________________________________________
elu_1 (ELU)                  (None, 32, 2048, 4)       0         
_________________________________________________________________
average_pooling2d_1 (Average (None, 16, 128, 4)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 128, 4)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 16, 128, 8)        4104      
_________________________________________________________________
elu_2 (ELU)                  (None, 16, 128, 8)        0         
_________________________________________________________________
average_pooling2d_2 (Average (None, 8, 16, 8)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 16, 8)          0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 8, 16, 16)         4112      
_________________________________________________________________
elu_3 (ELU)                  (None, 8, 16, 16)         0         
_________________________________________________________________
average_pooling2d_3 (Average (None, 4, 2, 16)          0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 2, 16)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                1935      
_________________________________________________________________
activation_1 (Activation)    (None, 15)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 48        
=================================================================
Total params: 26,075
Trainable params: 26,075
Non-trainable params: 0
_________________________________________________________________
avg accuracy 0.6411411425909839 over 5 splits
end time
Sat Apr  7 17:29:00 CEST 2018
slurmstepd: error: Exceeded step memory limit at some point.
