data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J lstm
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="lstm.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

CURR_DIR="$(pwd)"
cd $DATA_DIR
cp -r --parents DATA/Visual $SNIC_TMP
cd $CURR_DIR
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Model, Sequential
from keras.layers import Dense, Dropout, Flatten, Input, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import TimeDistributed
from keras.layers import Lambda, concatenate
from keras.layers import CuDNNLSTM, CuDNNGRU, SimpleRNN, RNN, LSTM, GRU

from keras.optimizers import SGD, Adam, RMSprop, Nadam
from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_single(cut=True, visual=True, transpose=True)
xt, yt = data.load_single(cut=True, visual=True, study=False, transpose=True)
    
print(x[0].shape, xt[0].shape)

splits = 10
n_subs = len(x)
n_models = 1
msets = [None for j in range(n_models)]
accs = [0 for j in range(n_models)]
accs2 = [0 for j in range(n_models)]


for j in range(n_models):

    msets[j] = " " # mset

    m_in = Input(shape=x[0][0].shape)

    m_t = LSTM(70, return_sequences=True)(m_in)
    m_t = Dropout(0.4)(m_t)
    m_t = LSTM(70)(m_t)
    m_t = Dropout(0.3)(m_t)

    m_t = Dense(15, activation='tanh')(m_t)
    m_out = Dense(3, activation='softmax')(m_t)

    model = Model(inputs=m_in, outputs=m_out)

    m_save = model.get_config()
    if j == 0:
        model.summary()

    avgacc = 0
    avgacc2 = 0
    for i in range(n_subs):
        n = x[i].shape[0]
        acc = 0
        acc2 = 0
        for tr, val in util.kfold(n, splits, shuffle=True):
            # recreate model
            model = Model.from_config(m_save)
            model.compile(loss='categorical_crossentropy',
                          optimizer='adam',
                          metrics=['accuracy'])
            # print(len(model.get_weights()))
            # print(model.get_weights()[0].shape)

            # fit with next kfold data
            h = model.fit(x[i][tr], y[i][tr],
                          # validation_data=(x[i][val], y[i][val]),
                          batch_size=64, epochs=100, verbose=0)
            h = h.history

            # vals += np.sum(np.absolute(model.get_weights()[0]), (0, 2))
            _, a = model.evaluate(x[i][val], y[i][val], verbose=0)
            _, a2 = model.evaluate(xt[i], yt[i], verbose=0)
            acc += a
            acc2 += a2

        K.clear_session()

        acc /= splits
        acc2 /= splits
        avgacc += acc
        avgacc2 += acc2

        print("subject {}, avg accuracy {}/{} over {} splits".format(i + 1 if i + 1 < 10 else i + 2,
                                                                     acc, acc2, splits))

    avgacc /= n_subs
    accs[j] = avgacc
    avgacc2 /= n_subs
    accs2[j] = avgacc2
    print("avg accuracy over all subjects {}/{}".format(avgacc, avgacc2))

# print("channel values")
# for v in vals:
    # print(v)

for a, a2 in sorted(zip(accs, accs2)):
    print("acc {}/{}\n".format(a, a2))

print("avg over all trials and subjects {}/{}".format(sum(accs) / len(accs), sum(accs2) / len(accs2)))
nvidia smi
Tue May 15 09:37:41 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   47C    P0   123W / 149W |  10975MiB / 11441MiB |     67%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   77C    P0   145W / 149W |  10975MiB / 11441MiB |     67%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   22C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   27C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0    314021      C   python                                     10962MiB |
|    1    314147      C   python                                     10962MiB |
+-----------------------------------------------------------------------------+
start time
Tue May 15 09:37:41 CEST 2018
DATA
2.4G	/local/slurmtmp.768263/DATA/Visual
2.4G	/local/slurmtmp.768263/DATA
copy done time
Tue May 15 09:37:43 CEST 2018
2018-05-15 09:37:44.501676: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-15 09:37:44.684555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:84:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-05-15 09:37:44.684675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 09:38:06.859649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 11:29:46.355121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 13:17:22.807227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 15:05:39.820086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 16:54:08.273446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 18:41:37.736386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 20:27:48.962039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 22:12:44.127913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-15 23:58:31.060475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 01:44:09.642452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 03:29:49.158127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 05:15:20.606127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 07:01:05.294469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 08:46:27.688806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 10:32:05.450608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 12:19:33.414209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 14:08:27.155611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
2018-05-16 15:57:06.412351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7)
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 6181237498730576745
, name: "/device:GPU:0"
device_type: "GPU"
memory_limit: 11325135258
locality {
  bus_id: 2
}
incarnation: 10598525498194107305
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:84:00.0, compute capability: 3.7"
]
loading:  Subj01_CleanData_study_FA
loading:  Subj01_CleanData_study_LM
loading:  Subj01_CleanData_study_OB
loading:  Subj02_CleanData_study_FA
loading:  Subj02_CleanData_study_LM
loading:  Subj02_CleanData_study_OB
loading:  Subj03_CleanData_study_FA
loading:  Subj03_CleanData_study_LM
loading:  Subj03_CleanData_study_OB
loading:  Subj04_CleanData_study_FA
loading:  Subj04_CleanData_study_LM
loading:  Subj04_CleanData_study_OB
loading:  Subj05_CleanData_study_FA
loading:  Subj05_CleanData_study_LM
loading:  Subj05_CleanData_study_OB
loading:  Subj06_CleanData_study_FA
loading:  Subj06_CleanData_study_LM
loading:  Subj06_CleanData_study_OB
loading:  Subj07_CleanData_study_FA
loading:  Subj07_CleanData_study_LM
loading:  Subj07_CleanData_study_OB
loading:  Subj08_CleanData_study_FA
loading:  Subj08_CleanData_study_LM
loading:  Subj08_CleanData_study_OB
loading:  Subj09_CleanData_study_FA
loading:  Subj09_CleanData_study_LM
loading:  Subj09_CleanData_study_OB
loading:  Subj11_CleanData_study_FA
loading:  Subj11_CleanData_study_LM
loading:  Subj11_CleanData_study_OB
loading:  Subj12_CleanData_study_FA
loading:  Subj12_CleanData_study_LM
loading:  Subj12_CleanData_study_OB
loading:  Subj13_CleanData_study_FA
loading:  Subj13_CleanData_study_LM
loading:  Subj13_CleanData_study_OB
loading:  Subj14_CleanData_study_FA
loading:  Subj14_CleanData_study_LM
loading:  Subj14_CleanData_study_OB
loading:  Subj15_CleanData_study_FA
loading:  Subj15_CleanData_study_LM
loading:  Subj15_CleanData_study_OB
loading:  Subj16_CleanData_study_FA
loading:  Subj16_CleanData_study_LM
loading:  Subj16_CleanData_study_OB
loading:  Subj17_CleanData_study_FA
loading:  Subj17_CleanData_study_LM
loading:  Subj17_CleanData_study_OB
loading:  Subj18_CleanData_study_FA
loading:  Subj18_CleanData_study_LM
loading:  Subj18_CleanData_study_OB
loading:  Subj19_CleanData_study_FA
loading:  Subj19_CleanData_study_LM
loading:  Subj19_CleanData_study_OB
loading:  Subj01_CleanData_test_FA_visual
loading:  Subj01_CleanData_test_LM_visual
loading:  Subj01_CleanData_test_OB_visual
loading:  Subj02_CleanData_test_FA_visual
loading:  Subj02_CleanData_test_LM_visual
loading:  Subj02_CleanData_test_OB_visual
loading:  Subj03_CleanData_test_FA_visual
loading:  Subj03_CleanData_test_LM_visual
loading:  Subj03_CleanData_test_OB_visual
loading:  Subj04_CleanData_test_FA_visual
loading:  Subj04_CleanData_test_LM_visual
loading:  Subj04_CleanData_test_OB_visual
loading:  Subj05_CleanData_test_FA_visual
loading:  Subj05_CleanData_test_LM_visual
loading:  Subj05_CleanData_test_OB_visual
loading:  Subj06_CleanData_test_FA_visual
loading:  Subj06_CleanData_test_LM_visual
loading:  Subj06_CleanData_test_OB_visual
loading:  Subj07_CleanData_test_FA_visual
loading:  Subj07_CleanData_test_LM_visual
loading:  Subj07_CleanData_test_OB_visual
loading:  Subj08_CleanData_test_FA_visual
loading:  Subj08_CleanData_test_LM_visual
loading:  Subj08_CleanData_test_OB_visual
loading:  Subj09_CleanData_test_FA_visual
loading:  Subj09_CleanData_test_LM_visual
loading:  Subj09_CleanData_test_OB_visual
loading:  Subj11_CleanData_test_FA_visual
loading:  Subj11_CleanData_test_LM_visual
loading:  Subj11_CleanData_test_OB_visual
loading:  Subj12_CleanData_test_FA_visual
loading:  Subj12_CleanData_test_LM_visual
loading:  Subj12_CleanData_test_OB_visual
loading:  Subj13_CleanData_test_FA_visual
loading:  Subj13_CleanData_test_LM_visual
loading:  Subj13_CleanData_test_OB_visual
loading:  Subj14_CleanData_test_FA_visual
loading:  Subj14_CleanData_test_LM_visual
loading:  Subj14_CleanData_test_OB_visual
loading:  Subj15_CleanData_test_FA_visual
loading:  Subj15_CleanData_test_LM_visual
loading:  Subj15_CleanData_test_OB_visual
loading:  Subj16_CleanData_test_FA_visual
loading:  Subj16_CleanData_test_LM_visual
loading:  Subj16_CleanData_test_OB_visual
loading:  Subj17_CleanData_test_FA_visual
loading:  Subj17_CleanData_test_LM_visual
loading:  Subj17_CleanData_test_OB_visual
loading:  Subj18_CleanData_test_FA_visual
loading:  Subj18_CleanData_test_LM_visual
loading:  Subj18_CleanData_test_OB_visual
loading:  Subj19_CleanData_test_FA_visual
loading:  Subj19_CleanData_test_LM_visual
loading:  Subj19_CleanData_test_OB_visual
(185, 768, 31) (90, 768, 31)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 768, 31)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 768, 70)           28560     
_________________________________________________________________
dropout_1 (Dropout)          (None, 768, 70)           0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 70)                39480     
_________________________________________________________________
dropout_2 (Dropout)          (None, 70)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 15)                1065      
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 48        
=================================================================
Total params: 69,153
Trainable params: 69,153
Non-trainable params: 0
_________________________________________________________________
subject 1, avg accuracy 0.3994152069091797/0.28888889057768713 over 10 splits
subject 2, avg accuracy 0.35818713903427124/0.321621622205586 over 10 splits
subject 3, avg accuracy 0.5046783685684204/0.383076923076923 over 10 splits
subject 4, avg accuracy 0.37953216284513475/0.3479166666666667 over 10 splits
subject 5, avg accuracy 0.4497076004743576/0.3403669733246532 over 10 splits
subject 6, avg accuracy 0.3807017594575882/0.33140495882546606 over 10 splits
subject 7, avg accuracy 0.39415204524993896/0.3402298845436381 over 10 splits
subject 8, avg accuracy 0.45263158082962035/0.32743362975595275 over 10 splits
subject 9, avg accuracy 0.44619883596897125/0.34337349358093305 over 10 splits
subject 11, avg accuracy 0.43479532599449155/0.31326530612244896 over 10 splits
subject 12, avg accuracy 0.4684210568666458/0.30210525948750344 over 10 splits
subject 13, avg accuracy 0.43596491813659666/0.3778761076188721 over 10 splits
subject 14, avg accuracy 0.3623684227466583/0.3486486493937067 over 10 splits
subject 15, avg accuracy 0.39707603454589846/0.3351999975919723 over 10 splits
subject 16, avg accuracy 0.34394736886024474/0.36451613403135735 over 10 splits
subject 17, avg accuracy 0.4684210568666458/0.3308823529411765 over 10 splits
subject 18, avg accuracy 0.3628654986619949/0.2771428574408804 over 10 splits
subject 19, avg accuracy 0.3921052679419518/0.34835164828614873 over 10 splits
avg accuracy over all subjects 0.41284275833103384/0.3345722975261985
acc 0.41284275833103384/0.3345722975261985

avg over all trials and subjects 0.41284275833103384/0.3345722975261985
end time
Wed May 16 17:47:26 CEST 2018
