data dir
/lunarc/nobackup/users/albheim/EEG-klassificering
script
#!/bin/sh
#SBATCH -t 60:00:00
#SBATCH -J allch
#SBATCH -A lu2018-2-3
#// SBATCH -o stdout_%j.out
#// SBATCH -e stderr_%j.err

# shold be lu or gpu
#SBATCH -p gpu

# how many gpus, 4 per node, using many seems to crash more often so stick with 1
#SBATCH --gres=gpu:1

# use 5 cores per GPU
#SBATCH -n 5
#SBATCH --mem-per-cpu=3100

DATA_DIR="$(cat ../data_location.txt)"
echo "data dir"
echo $DATA_DIR

echo "script"
cat $0

PY_FILE="conv2d_spect.py"
echo "py file"
cat $PY_FILE

echo "nvidia smi"
nvidia-smi

echo "start time"
date

cp -r "${DATA_DIR}/DATA" $SNIC_TMP
ls $SNIC_TMP
du -h "${SNIC_TMP}/DATA"

echo "copy done time"
date

#matlab -nodisplay -nosplash -nodesktop -r "run('../matlab/save transformed/savetf.m');"
python $PY_FILE $SNIC_TMP

echo "end time"
date
py file
import sys
from datetime import datetime

import numpy as np
from scipy import io

import tensorflow as tf

from keras.models import Model
from keras.layers import Dense, Dropout, Input, GaussianNoise, BatchNormalization
from keras.layers import Lambda
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import ELU, Activation, Flatten

from keras import backend as K

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import data
import util


x, y = data.load_spect()

print(x.shape)

splits = 5

# channels = [4, 23]
# for i in range(n_subs):
#     x[i] = x[i][:, :, channels]
#     xt[i] = xt[i][:, :, channels]


m_in = Input(shape=x[0].shape)

m_t = Conv2D(4, (8, 16), padding='same')(m_in)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 16))(m_t)
m_t = Dropout(0.2)(m_t)

m_t = Conv2D(8, (8, 16), padding='same')(m_t)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 8))(m_t)
m_t = Dropout(0.3)(m_t)

m_t = Conv2D(16, (4, 8), padding='same')(m_t)
#m_t = BatchNormalization()(m_t)
m_t = ELU()(m_t)
m_t = AveragePooling2D((2, 8))(m_t)
m_t = Dropout(0.4)(m_t)

m_t = Flatten()(m_t)
m_t = Dense(15)(m_t)
#m_t = BatchNormalization()(m_t)
m_t = Activation('tanh')(m_t)
m_out = Dense(3, activation='softmax')(m_t)

model = Model(inputs=m_in, outputs=m_out)

m_save = model.get_config()
model.summary()

acc = 0
for tr, val in util.kfold(len(x), splits, shuffle=True):

    model = Model.from_config(m_save)
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    # fit with next kfold data
    h = model.fit(x[tr], y[tr],
                  #validation_data=(x[val], y[val]),
                  batch_size=16, epochs=50, verbose=0)

    _, a = model.evaluate(x[val], y[val], verbose=0)
    acc += a

acc /= splits

print("avg accuracy {} over {} splits".format(acc, splits))
nvidia smi
Mon Apr  9 09:01:13 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   24C    P8    27W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   30C    P8    31W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   25C    P8    26W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   31C    P8    30W / 149W |      1MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
start time
Mon Apr  9 09:01:13 CEST 2018
DATA
2.4G	/local/slurmtmp.596544/DATA/Visual
2.4G	/local/slurmtmp.596544/DATA/Verbal
388M	/local/slurmtmp.596544/DATA/Modified/marginal
2.7G	/local/slurmtmp.596544/DATA/Modified/spectogram
3.1G	/local/slurmtmp.596544/DATA/Modified
7.8G	/local/slurmtmp.596544/DATA
copy done time
Mon Apr  9 09:02:30 CEST 2018
2018-04-09 09:02:31.603849: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
/home/albheim/.conda/envs/test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Traceback (most recent call last):
  File "conv2d_spect.py", line 18, in <module>
    print(device_lib.list_local_devices())
  File "/home/albheim/.conda/envs/test/lib/python3.6/site-packages/tensorflow/python/client/device_lib.py", line 36, in list_local_devices
    return [_convert(s) for s in pywrap_tensorflow.list_devices()]
  File "/home/albheim/.conda/envs/test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 1274, in list_devices
    return ListDevices(status)
  File "/home/albheim/.conda/envs/test/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY; total memory reported: 11995578368
end time
Mon Apr  9 09:02:31 CEST 2018
slurmstepd: error: Exceeded step memory limit at some point.
